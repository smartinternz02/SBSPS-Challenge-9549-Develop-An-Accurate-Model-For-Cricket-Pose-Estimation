{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a0cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62583ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing \n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils #Draw utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ec01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for detecting pose of the person using MideaPipe\n",
    "\n",
    "def multiple_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) # Color convertion \n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)                # Precessing the image via holistic model to generate pose keypoints\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR) # Color convertion again\n",
    "    return image,results                          # returning generated pose keypoints as results and image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8294a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2f082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe064f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3f4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data_path where your all extracted body pose keypoints files are saved frame-wise in .npy format\n",
    "DATA_PATH=r\"D:\\Cricket_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47477b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cover Drive', 'Helicopter', 'Late Cut', 'Pull', 'Straight Drive', 'Sweep']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions=os.listdir(DATA_PATH)\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6624b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e2a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cover Drive': 0,\n",
       " 'Helicopter': 1,\n",
       " 'Late Cut': 2,\n",
       " 'Pull': 3,\n",
       " 'Straight Drive': 4,\n",
       " 'Sweep': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab78634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))):\n",
    "        window = []\n",
    "        res = np.load(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be2b5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13798cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244a4891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 1, 1662)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8762a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc21c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "742d033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ac710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "170ea700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f92a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a8d7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d174b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3420, 1, 1662)\n",
      "(180, 1, 1662)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a948e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3420, 6)\n",
      "(180, 6)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26f8ef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8484dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e353d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(1, 1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(actions), activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50987a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.1126 - accuracy: 0.9518 - val_loss: 0.3031 - val_accuracy: 0.9196\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3033 - val_accuracy: 0.9196\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3041 - val_accuracy: 0.9167\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3017 - val_accuracy: 0.9211\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3035 - val_accuracy: 0.9196\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3030 - val_accuracy: 0.9196\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3043 - val_accuracy: 0.9196\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3044 - val_accuracy: 0.9167\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1125 - accuracy: 0.9481 - val_loss: 0.3056 - val_accuracy: 0.9181\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3044 - val_accuracy: 0.9181\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3043 - val_accuracy: 0.9181\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1125 - accuracy: 0.9518 - val_loss: 0.3048 - val_accuracy: 0.9196\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1126 - accuracy: 0.9477 - val_loss: 0.3055 - val_accuracy: 0.9196\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3037 - val_accuracy: 0.9181\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3068 - val_accuracy: 0.9152\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3048 - val_accuracy: 0.9196\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1125 - accuracy: 0.9488 - val_loss: 0.3067 - val_accuracy: 0.8977\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9507 - val_loss: 0.3060 - val_accuracy: 0.9196\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1125 - accuracy: 0.9518 - val_loss: 0.3069 - val_accuracy: 0.9196\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1125 - accuracy: 0.9518 - val_loss: 0.3073 - val_accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3056 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3057 - val_accuracy: 0.9196\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3089 - val_accuracy: 0.9181\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3075 - val_accuracy: 0.9181\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3073 - val_accuracy: 0.9196\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1125 - accuracy: 0.9518 - val_loss: 0.3071 - val_accuracy: 0.9181\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3086 - val_accuracy: 0.9196\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3091 - val_accuracy: 0.9181\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3090 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3081 - val_accuracy: 0.9196\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1125 - accuracy: 0.9518 - val_loss: 0.3094 - val_accuracy: 0.9181\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3090 - val_accuracy: 0.9196\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3106 - val_accuracy: 0.9181\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3090 - val_accuracy: 0.9181\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3092 - val_accuracy: 0.9196\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1127 - accuracy: 0.9518 - val_loss: 0.3112 - val_accuracy: 0.9196\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3101 - val_accuracy: 0.9181\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.1126 - accuracy: 0.9518 - val_loss: 0.3101 - val_accuracy: 0.9196\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9492 - val_loss: 0.3124 - val_accuracy: 0.8977\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3109 - val_accuracy: 0.9181\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3119 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1127 - accuracy: 0.9518 - val_loss: 0.3129 - val_accuracy: 0.9152\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3105 - val_accuracy: 0.9196\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1126 - accuracy: 0.9466 - val_loss: 0.3123 - val_accuracy: 0.8991\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9521 - val_loss: 0.3121 - val_accuracy: 0.9181\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3125 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3118 - val_accuracy: 0.9211\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1123 - accuracy: 0.9518 - val_loss: 0.3143 - val_accuracy: 0.9181\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3136 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.3137 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26886345f10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50,batch_size=128,shuffle = True,validation_split = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7c1470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 64)             442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,774\n",
      "Trainable params: 596,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e21aadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b88e757c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0a3e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4648547e-19, 4.7833406e-16, 9.9999988e-01, 1.2892329e-11,\n",
       "        9.6054409e-10, 1.2109030e-07],\n",
       "       [1.2161336e-19, 6.1333714e-28, 4.7579020e-30, 1.1094484e-22,\n",
       "        3.8185805e-10, 1.0000000e+00],\n",
       "       [1.4085560e-03, 9.9858958e-01, 1.8065070e-06, 3.4646747e-11,\n",
       "        3.5386576e-09, 3.1518493e-11],\n",
       "       [3.2127216e-01, 3.6163965e-01, 1.4213195e-01, 4.4351902e-02,\n",
       "        4.2903461e-02, 8.7700777e-02],\n",
       "       [1.8547825e-11, 1.0000000e+00, 6.1514690e-14, 3.0240974e-16,\n",
       "        3.6640358e-22, 2.4954952e-20]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bfdbb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[np.argmax(i) for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65610981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 1, 1, 1, 5, 4, 3, 0, 3]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "194d0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "baf731ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[np.argmax(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b26942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 1, 1, 1, 5, 4, 3, 0, 3]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d277f8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[147,   1],\n",
       "        [  1,  31]],\n",
       "\n",
       "       [[146,   4],\n",
       "        [  0,  30]],\n",
       "\n",
       "       [[148,   1],\n",
       "        [  5,  26]],\n",
       "\n",
       "       [[144,   0],\n",
       "        [  1,  35]],\n",
       "\n",
       "       [[154,   2],\n",
       "        [  4,  20]],\n",
       "\n",
       "       [[148,   5],\n",
       "        [  2,  25]]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f7cac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9277777777777778"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(actual,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3cadc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cricket_pose_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2b2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
